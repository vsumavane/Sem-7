{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCb5K7LlKq0"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u4A5r7OalKq2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXDC5-YMlKq3"
      },
      "source": [
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9IbgmRgilKq3",
        "outputId": "cc06d9ee-6852-41eb-e597-81e297778ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'heart.csv', 'sample_data']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n",
            "age:\t\t\tage\n",
            "sex:\t\t\t1: male, 0: female\n",
            "cp:\t\t\tchest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\n",
            "trestbps:\t\t\tresting blood pressure\n",
            "chol:\t\t\t serum cholestoral in mg/dl\n",
            "fbs:\t\t\tfasting blood sugar > 120 mg/dl\n",
            "restecg:\t\t\tresting electrocardiographic results (values 0,1,2)\n",
            "thalach:\t\t\t maximum heart rate achieved\n",
            "exang:\t\t\texercise induced angina\n",
            "oldpeak:\t\t\toldpeak = ST depression induced by exercise relative to rest\n",
            "slope:\t\t\tthe slope of the peak exercise ST segment\n",
            "ca:\t\t\tnumber of major vessels (0-3) colored by flourosopy\n",
            "thal:\t\t\tthal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir())\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset = pd.read_csv(\"heart.csv\")\n",
        "\n",
        "type(dataset)\n",
        "\n",
        "dataset.shape\n",
        "\n",
        "dataset.head(5)\n",
        "\n",
        "dataset.sample(5)\n",
        "\n",
        "dataset.describe()\n",
        "\n",
        "dataset.info()\n",
        "\n",
        "info = [\"age\",\"1: male, 0: female\",\"chest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\",\"resting blood pressure\",\" serum cholestoral in mg/dl\",\"fasting blood sugar > 120 mg/dl\",\"resting electrocardiographic results (values 0,1,2)\",\" maximum heart rate achieved\",\"exercise induced angina\",\"oldpeak = ST depression induced by exercise relative to rest\",\"the slope of the peak exercise ST segment\",\"number of major vessels (0-3) colored by flourosopy\",\"thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\"]\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(info)):\n",
        "    print(dataset.columns[i]+\":\\t\\t\\t\"+info[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVO9tgydlKq4"
      },
      "source": [
        "\"\"\"Analysing the 'target' variable\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sCbfBvfalKq4",
        "outputId": "f1b0b343-9227-46da-843a-64ddc27f8073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "dataset[\"target\"].describe()\n",
        "\n",
        "dataset[\"target\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh5inPGblKq5"
      },
      "source": [
        "\"\"\"Clearly, this is a classification problem, with the target variable having values '0' and '1'\n",
        "Checking correlation between columns\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bnzum_6mlKq5",
        "outputId": "3c6caa4a-e79f-45d2-ac79-b25f4f850f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target      1.000000\n",
            "exang       0.436757\n",
            "cp          0.433798\n",
            "oldpeak     0.430696\n",
            "thalach     0.421741\n",
            "ca          0.391724\n",
            "slope       0.345877\n",
            "thal        0.344029\n",
            "sex         0.280937\n",
            "age         0.225439\n",
            "trestbps    0.144931\n",
            "restecg     0.137230\n",
            "chol        0.085239\n",
            "fbs         0.028046\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(dataset.corr()[\"target\"].abs().sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iZJpVulKq5"
      },
      "source": [
        "# This shows that most columns are moderately correlated with target, but 'fbs' is very weakly correlated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwCE5XHklKq5"
      },
      "source": [
        "\"\"\"**Exploratory Data Analysis (EDA)**\n",
        "First, analysing the target variable:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R5V880PSlKq5",
        "outputId": "df21959a-6af7-4a41-e1ba-c88a1296d4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "1    165\n",
            "0    138\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y = dataset[\"target\"]\n",
        "\n",
        "sns.countplot(y)\n",
        "target_temp = dataset.target.value_counts()\n",
        "print(target_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwZ8Zq06lKq5"
      },
      "source": [
        "\"\"\"We'll analyse 'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca' and 'thal' features\n",
        "Analysing the 'Sex' feature\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3-u2JKe4lKq5",
        "outputId": "1bdeddc7-0313-45a2-bbf5-6de374270feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of patience without heart problems: 45.54\n",
            "Percentage of patience with heart problems: 54.46\n"
          ]
        }
      ],
      "source": [
        "print(\"Percentage of patience without heart problems: \"+str(round(target_temp[0]*100/303,2)))\n",
        "print(\"Percentage of patience with heart problems: \"+str(round(target_temp[1]*100/303,2)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev6mOosklKq5"
      },
      "source": [
        "## Alternatively,\n",
        "### print(\"Percentage of patience with heart problems: \"+str(y.where(y==1).count()*100/303))\n",
        "### print(\"Percentage of patience with heart problems: \"+str(y.where(y==0).count()*100/303))\n",
        "\n",
        "### Or, countNoDisease = len(df[df.target == 0]) countHaveDisease = len(df[df.target == 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrFzFo3elKq6"
      },
      "source": [
        "We'll analyse 'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca' and 'thal' features.\n",
        "\n",
        "Analysing the 'Sex' feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5FigrMKulKq6",
        "outputId": "4f170a1d-0897-48eb-a9dc-ea97805d39eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='sex'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "dataset[\"sex\"].unique()\n",
        "\n",
        "sns.barplot(dataset[\"sex\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpC8aeUzlKq6"
      },
      "source": [
        "IV. Train Test split\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Qh7mZx2HlKq6",
        "outputId": "90879f62-91e8-4503-e635-ee024866e59f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "predictors = dataset.drop(\"target\", axis=1)\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(predictors, target, test_size=0.20, random_state=0)\n",
        "\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "Y_train.shape\n",
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5scS24DlKq6"
      },
      "source": [
        "\"\"\"V. Model Fitting\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "psv3NDOZlKq6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNGCv44NlKq6"
      },
      "source": [
        "\"\"\"Logistic Regression\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n1WZGElllKq6",
        "outputId": "ca4b0355-aa58-40ce-953f-9ad3b88ed53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using Logistic Regression is: 85.25 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83        26\n",
            "           1       0.88      0.86      0.87        35\n",
            "\n",
            "    accuracy                           0.85        61\n",
            "   macro avg       0.85      0.85      0.85        61\n",
            "weighted avg       0.85      0.85      0.85        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "Y_pred_lr.shape\n",
        "\n",
        "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "print(classification_report(Y_pred_lr,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz3OMnwdlKq6"
      },
      "source": [
        "\"\"\"Naive Bayes\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AXqbwZAtlKq7",
        "outputId": "ccd97260-a34f-4391-94e7-9f5f6698def8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using Naive Bayes is: 85.25 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.82        24\n",
            "           1       0.91      0.84      0.87        37\n",
            "\n",
            "    accuracy                           0.85        61\n",
            "   macro avg       0.84      0.86      0.85        61\n",
            "weighted avg       0.86      0.85      0.85        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "Y_pred_nb.shape\n",
        "\n",
        "score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_nb,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5de9lm3tlKq7"
      },
      "source": [
        "\"\"\"SVM\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "INXU40EDlKq7",
        "outputId": "3d7485ba-4c63-4c2a-a841-6b59fb42f594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using Linear SVM is: 81.97 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78        24\n",
            "           1       0.88      0.81      0.85        37\n",
            "\n",
            "    accuracy                           0.82        61\n",
            "   macro avg       0.81      0.82      0.81        61\n",
            "weighted avg       0.83      0.82      0.82        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "sv = svm.SVC(kernel='linear')\n",
        "\n",
        "sv.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred_svm = sv.predict(X_test)\n",
        "\n",
        "Y_pred_svm.shape\n",
        "\n",
        "score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_svm,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obkuORcslKq7"
      },
      "source": [
        "K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M81st3jllKq7",
        "outputId": "c8d95402-5b34-43dc-cc6b-de0253a5f23f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using KNN is: 67.21 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.62      0.64        29\n",
            "           1       0.68      0.72      0.70        32\n",
            "\n",
            "    accuracy                           0.67        61\n",
            "   macro avg       0.67      0.67      0.67        61\n",
            "weighted avg       0.67      0.67      0.67        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train,Y_train)\n",
        "Y_pred_knn=knn.predict(X_test)\n",
        "\n",
        "Y_pred_knn.shape\n",
        "\n",
        "score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_knn,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHlW9-O1lKq7"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fCtzy16ElKq7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "max_accuracy = 0\n",
        "\n",
        "\n",
        "for x in range(200):\n",
        "    dt = DecisionTreeClassifier(random_state=x)\n",
        "    dt.fit(X_train,Y_train)\n",
        "    Y_pred_dt = dt.predict(X_test)\n",
        "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
        "    if(current_accuracy>max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZHrLgkX9lKq7",
        "outputId": "b848e5a9-1493-4704-e4de-70ed8443cd06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61,)\n",
            "The accuracy score achieved using Decision Tree is: 81.97 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80        28\n",
            "           1       0.82      0.85      0.84        33\n",
            "\n",
            "    accuracy                           0.82        61\n",
            "   macro avg       0.82      0.82      0.82        61\n",
            "weighted avg       0.82      0.82      0.82        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier(random_state=best_x)\n",
        "dt.fit(X_train,Y_train)\n",
        "Y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "print(Y_pred_dt.shape)\n",
        "\n",
        "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_dt,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVD-eX9AlKq7"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1AphWb7xlKq7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "max_accuracy = 0\n",
        "\n",
        "\n",
        "for x in range(2000):\n",
        "    rf = RandomForestClassifier(random_state=x)\n",
        "    rf.fit(X_train,Y_train)\n",
        "    Y_pred_rf = rf.predict(X_test)\n",
        "    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
        "    if(current_accuracy>max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TZuhdabGlKq8",
        "outputId": "574d1758-ab52-4613-800a-dc7a22bb29ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using Decision Tree is: 90.16 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88        25\n",
            "           1       0.94      0.89      0.91        36\n",
            "\n",
            "    accuracy                           0.90        61\n",
            "   macro avg       0.90      0.90      0.90        61\n",
            "weighted avg       0.90      0.90      0.90        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(random_state=best_x)\n",
        "rf.fit(X_train,Y_train)\n",
        "Y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "Y_pred_rf.shape\n",
        "\n",
        "score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_rf)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_rf,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc60FjS4lKq8"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PZqXEb41lKq8",
        "outputId": "8892f4a4-c9fa-4706-b89b-b336e1aea0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using XGBoost is: 83.61 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81        27\n",
            "           1       0.85      0.85      0.85        34\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.83      0.83      0.83        61\n",
            "weighted avg       0.84      0.84      0.84        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "xgb_model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "Y_pred_xgb.shape\n",
        "\n",
        "score_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using XGBoost is: \"+str(score_xgb)+\" %\")\n",
        "\n",
        "print(classification_report(Y_pred_xgb,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VIfuSsClKq8"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "YUVdbUJ2lKq8",
        "outputId": "82ee247a-779f-4591-b172-2f6b0a431f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 1s 6ms/step - loss: 10.7103 - accuracy: 0.4587\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2237 - accuracy: 0.4587\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1772 - accuracy: 0.6322\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4353 - accuracy: 0.6240\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1701 - accuracy: 0.6198\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8639 - accuracy: 0.6529\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.6570\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7569 - accuracy: 0.6818\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6488\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7422 - accuracy: 0.6653\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.6653\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7335 - accuracy: 0.6736\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.6901\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.6860\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.6818\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.6901\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.6901\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.7066\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.6860\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.6942\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7025\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6942\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6901\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6942\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6860\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6983\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.7025\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6901\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.7025\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6983\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6242 - accuracy: 0.6983\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6264 - accuracy: 0.7107\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6233 - accuracy: 0.7107\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.6942\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.6942\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6983\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7107\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.7107\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7149\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7107\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6901\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6029 - accuracy: 0.7149\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7025\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7107\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7149\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7231\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7231\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7066\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7025\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7149\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7273\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7314\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7397\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7397\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7355\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7397\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7397\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7397\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7479\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7562\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7397\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7645\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7438\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7727\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7479\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7562\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7603\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7603\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7810\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7727\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7851\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7603\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7810\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7769\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7934\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7769\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7975\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7893\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7893\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7562\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7810\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7727\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8017\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7934\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7934\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7934\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7934\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7645\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7686\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7810\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7975\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7851\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7851\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7934\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7934\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7934\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7810\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8140\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8017\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7769\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7975\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7810\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8017\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7934\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8017\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.7934\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7851\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8140\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7934\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8223\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7975\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7975\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.7975\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8058\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8140\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.7975\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8347\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.7934\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8099\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8347\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8223\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8264\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8306\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8264\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8223\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.7934\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7934\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7975\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8347\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.7810\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8223\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8306\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8306\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8099\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8223\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8017\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8347\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8099\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8264\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8182\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8182\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8264\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8182\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8264\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8058\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8388\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8306\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8264\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8223\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8264\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8264\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8058\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8099\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8388\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8223\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8223\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.7975\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8347\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8306\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8058\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8388\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8430\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8182\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8430\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8182\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8264\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8099\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8223\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8347\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8264\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8347\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8182\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8306\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8471\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8388\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8264\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8264\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8140\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8347\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8430\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8182\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8347\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.7934\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8388\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8140\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8388\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8306\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8306\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8430\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8388\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8182\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8182\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8140\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8347\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8140\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8388\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8347\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8306\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8388\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8306\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8388\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8430\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8306\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8140\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8140\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8306\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8264\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8306\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8264\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8388\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8306\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8223\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8306\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8264\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8388\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8306\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8347\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8182\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8388\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8182\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8182\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8058\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8306\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8223\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8388\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8182\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8264\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8388\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8388\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8264\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8306\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8430\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8430\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8264\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8430\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8347\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8223\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8388\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8182\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8471\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8264\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8306\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8306\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8306\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8140\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8471\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8430\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8388\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8347\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8388\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8430\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8223\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8223\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8388\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8182\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8347\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8182\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8430\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8347\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8347\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8182\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8430\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8347\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8223\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8306\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8264\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8264\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8264\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8223\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8388\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8264\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8140\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8182\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8306\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8182\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8140\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7934\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8264\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8306\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8306\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8264\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8512\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8140\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8306\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8347\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8430\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8388\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8430\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8264\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8471\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8388\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8388\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8306\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8140\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8306\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8182\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8306\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8264\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8430\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8388\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "The accuracy score achieved using Neural Network is: 81.97 %\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# https://stats.stackexchange.com/a/136542 helped a lot in avoiding overfitting\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(11,activation='relu',input_dim=13))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,Y_train,epochs=300)\n",
        "\n",
        "Y_pred_nn = model.predict(X_test)\n",
        "\n",
        "Y_pred_nn.shape\n",
        "\n",
        "rounded = [round(x[0]) for x in Y_pred_nn]\n",
        "\n",
        "Y_pred_nn = rounded\n",
        "\n",
        "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKX-dqrZlKq8"
      },
      "source": [
        "# Note: Accuracy of 85% can be achieved on the test set, by setting epochs=2000, and number of nodes = 11.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "abtPsoP5lKrC",
        "outputId": "0ae56c02-81cd-4704-892d-12b2e7c0433c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79        26\n",
            "           1       0.85      0.83      0.84        35\n",
            "\n",
            "    accuracy                           0.82        61\n",
            "   macro avg       0.82      0.82      0.82        61\n",
            "weighted avg       0.82      0.82      0.82        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_pred_nn,Y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYaKSyRflKrC"
      },
      "source": [
        "VI. Output final score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WOf81PRdlKrC",
        "outputId": "2275fe04-87f1-480e-e72b-e6b5c5d36a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using Logistic Regression is: 85.25 %\n",
            "The accuracy score achieved using Naive Bayes is: 85.25 %\n",
            "The accuracy score achieved using Support Vector Machine is: 81.97 %\n",
            "The accuracy score achieved using K-Nearest Neighbors is: 67.21 %\n",
            "The accuracy score achieved using Decision Tree is: 81.97 %\n",
            "The accuracy score achieved using Random Forest is: 90.16 %\n",
            "The accuracy score achieved using XGBoost is: 83.61 %\n",
            "The accuracy score achieved using Neural Network is: 81.97 %\n"
          ]
        }
      ],
      "source": [
        "scores = [score_lr,score_nb,score_svm,score_knn,score_dt,score_rf,score_xgb,score_nn]\n",
        "algorithms = [\"Logistic Regression\",\"Naive Bayes\",\"Support Vector Machine\",\"K-Nearest Neighbors\",\"Decision Tree\",\"Random Forest\",\"XGBoost\",\"Neural Network\"]\n",
        "\n",
        "for i in range(len(algorithms)):\n",
        "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}